#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""This module wraps h5py to be able to store almost any native Python type, as
well as instances of user-defined classes, in a HDF5 file. The list of
supported data structures includes:

- list, tuple, set, frozenset (may also be nested in any possible way, and  may
  also be empty)
- dict
- int, float, long, complex
- str

User-defined classes (to be particular: Those variables that possess an
attribute named "__module__") are serialized using the cPickle module and then
stored as a normal string into the HDF5 file. To restore the objects, the
module where the class definition exists must be present at exactly the same
place (and under the same name) like when the object was written to the HDF5
file (this is a requirement of the module cPickle to work correctly).

The created HDF5 datasets and groups get special attributes to retrieve the
right type of each Python object (__DTYPE__, __NTYPE__) and to store information
about a user-defined class (__CLASS__, __MODULE__), so that the object can be
reconstructed later. These attributes must of course not be overwritten or
deleted by any 3rd party software, otherwise the objects may not be restored
in the right format (cannot be casted to the right type).

Additionally, each created HDF5 dataset or group will get an attribute named
__DATE__, containing a current time stamp of the time when the object was
written to the HDF5 file.

Written by Daniel Jung, Jacobs University Bremen, Germany (2011).
"""
# 2011-10-21 until 2012-04-26
#from h5py import File as h5pyFile
#from h5py import Group as h5pyGroup
from tb.misc import dump as _dump

def obj2hdf(f, **objects):
  """Store objects in a HDF5 file, referenced by the h5py.File object f.
  Depending on the object type, it either just creates a suitable HDF5 dataset,
  or it may create multiple nested HDF5 groups, together with certain
  attributes and datasets, to represent the Python object. name=object value
  pairs have to be specified using keyword arguments."""
  # 2011-11-15 until 2012-02-19
  # former h5obj._create_obj from 2011-10-21 until 2011-10-25
  # former tb.savehdf from 2011-02-05 until 2011-03-30
  from time import ctime

  # loop over all given names and data objects
  for name, data in objects.iteritems():
    # get types
    dtype = type(data).__name__
    ntype = type(name).__name__
    #dump(dtype=dtype, name=name, data=data, ntype=ntype); print

    # initialize pickle state
    pickled = False

    # convert non-string names to string
    if ntype != 'str':
      name = repr(name)

    # overwrite existing dataset
    if name in f:
      del(f[name])

    # distinguish object types
    if data is None:
      # None type
      new = f.create_dataset(name, data='__NONE__')
    elif dtype == 'bool':
      # boolean type
      new = f.create_dataset(name, data=data)
    elif dtype in ('int', 'float', 'long', 'complex'):
      # built-in numeric types
      new = f.create_dataset(name, data=data)
    elif dtype == 'str':
      # string
      new = f.create_dataset(name, data=data)
      ### can unicode be supported?
    elif dtype in ('list', 'tuple'):
      if len(data) == 0:
        new = f.create_dataset(name, data='__EMPTY__')
      elif _allscalar(data) and _equaltype(data) and not _anyobject(data):
        # then, a normal dataset can be used
        new = f.create_dataset(name, data=data)
      else:
        # a HDF5 group has to be used to store the sequence
        new = f.create_group(name)
        keys = ['key%s' % k for k in xrange(len(data))]
        obj2hdf(new, **dict(zip(keys, data)))
    elif dtype in ('set', 'frozenset'):
      if len(data) == 0:
        new = f.create_dataset(name, data='__EMPTY__')
      elif _allscalar(data) and _equaltype(data):
        ### why not check anyobject here?
        new = f.create_dataset(name, data=tuple(data))
      else:
        # Use HDF5 group
        new = f.create_group(name)
        keys = ['key%s' % k for k in xrange(len(data))]
        obj2hdf(new, **dict(zip(keys, tuple(data))))
    elif dtype == 'dict':
      new = f.create_group(name)
      obj2hdf(new, **data)
    elif dtype in ('ndarray', 'matrix'):
      if 0 in data.shape:
        # Empty array or matrix. Save string representation
        new = f.create_dataset(name, data='__EMPTY__')
      else:
        new = f.create_dataset(name, data=data)
    elif dtype in ('csc_matrix', 'csr_matrix', 'bsr_matrix', 'lil_matrix',
                    'dok_matrix', 'coo_matrix', 'dia_matrix'):
      # The classes could simply be serialized, but then, other people would
      # have no chance to read the matrices with their own programs
      if dtype != 'csr_matrix':
        # Convert to csr_matrix:
        data = data.tocsr()
      new = f.create_group(name)
      obj2hdf(new, data=data.data, indices=data.indices, indptr=data.indptr,
              shape=data.shape, dtype=dtype)
    elif dtype == 'struct':
      #print 'hello %s' % name
      # Only with struct it is possible to use a group, not with dict, because
      # dict may have non-string keys. So, dict has to be pickled
      #print 'found struct %s' % name
      if name in f:
        del(f[name]) # Overwrite
      new = f.create_group(name)
      obj2hdf(new, **data)
    else:
      # Serialize the object using cPickle
      from cPickle import dumps
      new = f.create_dataset(name, data=dumps(data))
      pickled = True

      #raise TypeError, 'datatype not supported: %s' % dtype

    # Always store types and current date and time in form of HDF5 attributes
    new.attrs.create('__DTYPE__', dtype)
    new.attrs.create('__NTYPE__', ntype)
    new.attrs.create('DATE', ctime())
    new.attrs.create('__PICKLED__', pickled)

    # If the object has attributes named __module__ or __class__, store them
    # They are important to recreate objects of user-defined classes
    try:
      f.attrs.create('__MODULE__', data.__module__)
    except AttributeError:
      pass
    try:
      f.attrs.create('__CLASS__', data.__class__.__name__)
    except AttributeError:
      pass
















def hdf2obj(f, *names):
  """Read Python objects that are stored in a HDF5 file, referenced by the
  h5py.File object identifier f."""
  # 2011-11-15 until 2012-04-26
  # former h5obj._get_obj from 2011-10-25
  # former tb.savehdf from 2011-02-05 until 2011-03-30
  from structure import struct

  # initialize value array
  values = []

  for name in names:
    if name not in f:
      raise KeyError,\
        'no dataset or group named %s in HDF5 file object' % name

    # avoid unicode names
    #name = str(name)

    # get object
    obj = f[name]

    # Load attributes
    dtype     = obj.attrs.get('__DTYPE__',   None)
    ntype     = obj.attrs.get('__NTYPE__',   None)
    module    = obj.attrs.get('__MODULE__',  None)
    classname = obj.attrs.get('__CLASS__',   None)
    pickled   = obj.attrs.get('__PICKLED__', False)

    # distinguish data types
    if pickled:
      # Then it's easy, just unpickle the object
      from cPickle import loads
      value = loads(obj.value)
    elif dtype == 'NoneType':
      value = None
    elif dtype == 'bool':
      value = obj.value
    elif dtype == 'int':
      value = int(obj.value)
    elif dtype == 'long':
      value = long(obj.value)
    elif dtype == 'float':
      value = float(obj.value)
    elif dtype == 'complex':
      value = complex(obj.value)
    elif dtype == 'str':
      value = str(obj.value)
    elif dtype == 'list':
      if type(obj).__name__ == 'Group':
        keys = obj.keys()
        keys.sort()
        value = []
        for key in keys:
          value.append(hdf2obj(obj, key))
          #value.append(obj[key].value)
      elif type(obj.value).__name__ == 'string_' and obj.value == '__EMPTY__':
        value = []
      else:
        # plain lists that were saved as a normal 1D array dataset
        value = list(obj.value)
    elif dtype == 'tuple':
      if type(obj).__name__ == 'Group':
        keys = obj.keys()
        keys.sort()
        value = []
        for key in keys:
          value.append(hdf2obj(obj, key))
          #value.append(obj[key].value)
        value = tuple(value)
      elif type(obj.value).__name__ == 'string_' and obj.value == '__EMPTY__':
        value = ()
      else:
        # Plain tuples that were saved as a normal 1D array dataset
        value = tuple(obj.value)
    elif dtype == 'set':
      if type(obj).__name__ == 'Group':
        keys = obj.keys()
        value = []
        for key in keys:
          value.append(hdf2obj(obj, key))
        value = set(value)
      elif type(obj.value).__name__ == 'string_' and obj.value == '__EMPTY__':
        # empty sets
        value = set()
      else:
        # sets that were saved as a 1D ndarray
        value = set(obj.value)
    elif dtype == 'frozenset':
      if type(obj).__name__ == 'Group':
        keys = obj.keys()
        value = []
        for key in keys:
          value.append(hdf2obj(obj, key))
        value = frozenset(value)
      elif type(obj.value).__name__ == 'string_' and obj.value == '__EMPTY__':
        # empty frozensets
        value = frozenset()
      else:
        # frozensets that were saved as a 1D ndarray
        value = frozenset(obj.value)
    elif dtype == 'struct':
      value = {}
      for key in obj.iterkeys():
        value[key] = hdf2obj(obj, key)
    elif dtype == 'dict':
      from cPickle import loads
      value = loads(obj.value)

      #value = {}
      #for key in obj.iterkeys():
        #ntype = obj[key].attrs.get('__NTYPE__', 'str')
        #if ntype == 'str':
          #value[key] = obj.get_obj(key)
        #else:
          #value[eval(key)] = obj.get_obj(key)
    elif dtype == 'ndarray':
      from numpy import array
      value = array(obj.value)
    elif dtype == 'matrix':
      from numpy import matrix
      value = matrix(obj.value)
    elif dtype in ('csc_matrix', 'csr_matrix', 'bsr_matrix', 'lil_matrix',
                   'dok_matrix', 'coo_matrix', 'dia_matrix'):
      # sparse matrices are always saved in CSR format
      # convert back to original format
      shape   = hdf2obj(obj, 'shape')
      data    = hdf2obj(obj, 'data')
      indices = hdf2obj(obj, 'indices')
      indptr  = hdf2obj(obj, 'indptr')
      from scipy.sparse import csr_matrix
      value = csr_matrix((data, indices, indptr),
                         shape=shape).asformat(dtype[:3])
    else:
      # then assume it is just a normal dataset representing whatever it
      # contains. If obj is a HDF5 group, return contents in form of a struct
      if type(obj).__name__ == 'Group':
        value = struct()
        for key in obj.keys():
          value[key] = hdf2obj(obj, key)
      else:
        value = obj.value

      #raise TypeError, 'datatype not supported: %s' % dtype

    # collect values
    values.append(value)

  # return values
  if len(values) == 1:
    return values[0]
  else:
    return values

















#=============================#
# Functions for type checking #
#=============================#

def _allscalar(seq):
  """Test if all elements of the sequence or set are scalar."""
  # 2011-09-13
  # former tb.allscalar from 2011-03-30
  for element in seq:
    if _isiterable(element):
      return False
    return True

def _anyobject(seq):
  """Test if any element of the sequence or set is an instance of a
  user-defined class."""
  # 2011-09-13
  # former tb.anyobject from 2011-03-30
  for element in seq:
    if _isobject(element):
      return True
  return False

def _equaltype(seq):
  """Test if all elements of the sequence or set have the same type."""
  # 2011-09-13
  # former tb.equaltype from 2011-03-30
  seq = list(seq)
  first = seq.pop()
  for element in seq:
    if type(element).__name__ != type(first).__name__:
      return False
  return True

def _isiterable(obj):
  """Check if an object is iterable. Return True for lists, tuples,
  dictionaries and numpy arrays (all objects that possess an __iter__ method).
  Return False for scalars (float, int, etc.), strings, bool and None."""
  # 2011-09-13
  # former tb.isiterable from 2011-01-27
  # former mytools.isiterable
  # Inicial idea from
  # http://bytes.com/topic/python/answers/514838-how-test-if-object-sequence-
  # iterable:
  # return isinstance(obj, basestring) or getattr(obj, '__iter__', False)
  # I found this to be better:
  return not getattr(obj, '__iter__', False) == False

def _isobject(obj):
  """Return True if obj possesses an attribute called "__dict__", otherwise
  return False."""
  # 2011-09-13
  # former tb.isobject from 2011-02-09
  # former mytools.isobject
  return not getattr(obj, '__dict__', False) == False
